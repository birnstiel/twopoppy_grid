{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dust-line Mass calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The surface density estimate after Powell et al. 2017 but accounting properly for pre-factors is\n",
    "\n",
    "$$\\Sigma_\\mathsf{g} = \\frac{\\gamma}{2} \\frac{t_\\mathsf{disk}\\, v_0 \\, \\rho_\\mathsf{s} \\, \\lambda}{r}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Powell et al. 2019\n",
    "\n",
    "$$\\Sigma_\\mathsf{g} = \\frac{2.5}{2 \\pi} \\frac{t_\\mathsf{disk}\\, v_0 \\, \\rho_\\mathsf{s} \\, \\lambda}{r}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: Powell pre-factor is $\\sim 0.4$, our pre-factor is $\\sim 1.4$, so we are about 3.5 times more massive. This does agree roughly with how much we over-predict the mass. Looks like they dropped about the right amount of pre factors to get the right result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our logit part reads\n",
    "\n",
    "$$\n",
    "y = 1 - \\frac{A}{1 + \\exp\\left(-\\frac{x - x_0}{\\Delta x}\\right)}\n",
    "$$\n",
    "\n",
    "which goes from 1 for small $x$ to $1-A$ for large $x$. \n",
    "\n",
    "If we want to be $N=90\\%$ towards the right limit, we need to go to\n",
    "\n",
    "$$x_r = x_0 + \\Delta x  \\log \\left(\\frac{N}{1 - N}\\right)$$\n",
    "\n",
    "We picked $\\Delta x$ to be $0.1 \\, x_0$, so the dust line would be at\n",
    "\n",
    "$$x = x_0 (1 + 0.1 \\ln(9)) \\simeq 1.22 x_0$$\n",
    "\n",
    "If we want to be at $N=90\\%$ in log space, we need to go to\n",
    "\n",
    "$$\n",
    "x_r = x_0 + \\Delta x \\ln\\left(\\frac{A}{(1 - A)^N + A - 1} - 1\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dust and gas surface densities from simulation and Powell method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "v_0 &= \\frac{c_s^2}{2  V_k}\\\\\n",
    "\\Sigma_d &= \\frac{\\lambda}{2 f} \\frac{v_0}{V_k} \\, \\rho_s \\, \\gamma\\\\\n",
    "&= \\frac{a}{10 cm} \\left(\\frac{\\frac{h}{r}}{0.1}\\right)^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo:\n",
    "\n",
    "- try at different times\n",
    "- randomize times\n",
    "- fix missing low(?) alpha analysis.\n",
    "- try to get a reasonable expression/fit of the error curve for proper calibration.\n",
    "- try to find out why some simulations are off by *a lot*\n",
    "- try the *original Powell* method: fitting just truncated power-laws and then fitting a self-similar profile.\n",
    "- find out why the mass is still well reproduced even if the surface densities are off by *a lot*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import corner\n",
    "\n",
    "import dipsy\n",
    "import estimator\n",
    "import analysis_mass\n",
    "\n",
    "import dipsy.data_frame_functions as ddff\n",
    "\n",
    "M_sun = dipsy.cgs_constants.M_sun\n",
    "year = dipsy.cgs_constants.year\n",
    "au = dipsy.cgs_constants.au\n",
    "year = dipsy.cgs_constants.year\n",
    "lams = analysis_mass.lams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_fraction = 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'dustlines.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_disk = 3e6 * year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading file and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dipsy.utils.read_from_hdf5('dustlines_mass_3.0e+06yr_f3.hdf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we add a column `error` to select based on its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['error'] = df.M_est/df.M_gas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['v_frag', 'alpha', 'Mdisk', 'r_c', 'M_star']\n",
    "\n",
    "# We also define the \"nice names\" of each parameter for the labels\n",
    "\n",
    "param_label = {\n",
    "    'alpha': r'$\\alpha$',\n",
    "    'v_frag': r'$v_\\mathsf{frag}$',\n",
    "    'Mdisk': r'$M_\\mathsf{disk}$',\n",
    "    'M_star': r'$M_\\star$',\n",
    "    'r_c': r'$r_\\mathsf{c}$',\n",
    "    'M_gas': '$M_\\mathrm{gas}$ [$M_\\star$]',\n",
    "    'M_est': r'$M_\\mathrm{gas,estim.}$'\n",
    "}\n",
    "\n",
    "param_values = ddff.get_param_values(df, param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('we have the following parameters:')\n",
    "for key, value in param_values.items():\n",
    "    print((key + f'({len(value)}):').ljust(15), end='')\n",
    "    print(', '.join([f'{v:.2g}' for v in value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the relation between estimate and true gas mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k in ['M_est', 'M_lbp_med']:\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(1e-4, .3)\n",
    "    ax.set_ylim(1e-4, 1e1)\n",
    "\n",
    "    ax.hexbin(df['M_gas'] / M_sun, df[k]/ M_sun, gridsize=(50,50),\n",
    "              xscale='log', yscale='log', vmax=20,\n",
    "              rasterized=False, cmap='cividis',\n",
    "              linewidths=0.01, edgecolor='face')\n",
    "\n",
    "    ax.plot([1e-4, 1e1], [1e-4, 1e1], 'w--')\n",
    "\n",
    "    _x = np.array([1e-4, 1e1])\n",
    "    _y = 0.15 * (_x/0.1)**0.8\n",
    "\n",
    "    ax.loglog(_x, _y, 'r-')\n",
    "    ax.set_xlabel(param_label['M_gas'])\n",
    "    ax.set_ylabel(param_label['M_est']);\n",
    "\n",
    "    f.savefig(f'heat_value_{k}.pdf', dpi=300, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the same but in terms of error = deviation from true solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['M_gas']\n",
    "y = df['M_est']/df['M_gas']\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "ax.set_xlim(1e-4, .3)\n",
    "ax.set_ylim(df.error.min(), 1e4)\n",
    "\n",
    "ax.hexbin(x / M_sun, y, gridsize=50,\n",
    "          xscale='log', yscale='log', vmax=20,\n",
    "          rasterized=False, cmap='cividis',\n",
    "          linewidths=0.2, edgecolor='face')\n",
    "ax.axhline(1.0, c='w', ls='--')\n",
    "\n",
    "ax.set_xlabel(param_label['M_gas'])\n",
    "ax.set_ylabel(r'$M_\\mathrm{gas,estim.} / M_\\mathrm{gas}$');\n",
    "\n",
    "f.savefig('heat_error.pdf', dpi=300, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_min = df.error.min()\n",
    "e_max = df.error.max()\n",
    "M_min = df.M_gas.min()\n",
    "M_max = df.M_gas.max()\n",
    "fact = np.log(e_max/e_min) / np.log(M_max/M_min)\n",
    "n_bin = 40\n",
    "\n",
    "param_values2 = {\n",
    "    'error': np.logspace(-1, 4, int((n_bin+1) * fact)),\n",
    "    'M_gas': np.logspace(-4, np.log10(.3), (n_bin+1)) * M_sun   \n",
    "}\n",
    "\n",
    "param_interfaces2 = ddff.make_interfaces(param_values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, x_c, y_c = np.histogram2d(\n",
    "    df.M_gas,\n",
    "    df.error,\n",
    "    bins=[\n",
    "        param_interfaces2['M_gas'],\n",
    "        param_interfaces2['error'],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.loglog(param_values2['M_gas'] / M_sun,\n",
    "          np.convolve(\n",
    "              (param_values2['error'] * counts).mean(1),\n",
    "              np.ones(5)/5, mode='same')\n",
    "         )\n",
    "ax.loglog(param_values2['M_gas'] / M_sun,\n",
    "          #np.convolve(\n",
    "              np.median((param_values2['error'] * counts), 1),\n",
    "          #    np.ones(5)/5, mode='same')\n",
    "         )\n",
    "ax.set_ylim(bottom=2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_aspect('equal')\n",
    "ax.pcolormesh(x_c/M_sun, y_c, counts.T, vmax=counts.max() * 0.5)\n",
    "ax.axhline(1, c='w', ls='--')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(param_label['M_gas'])\n",
    "ax.set_ylabel('error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply the filter function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two plots that follow show the fraction of good estimates per bin. If the value is 100% in a bin, then all those simulations were well estimated. For testing this, one can set\n",
    "```\n",
    "df['error'] = 1\n",
    "```\n",
    "before the filter function is called (i.e. before `res` is calculated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda row: ddff.filter_function(row, error=[0.3, 3])\n",
    "res = df[df.apply(f, axis=1)].copy()\n",
    "print(f'found {len(res)} matching simulations ({len(res) / len(df):.1%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ddff.histogram_corner(res, param_values, param_label=param_label,\n",
    "                          percent='per_bin', n_total=len(df), vmax=100)\n",
    "f.savefig('histogram_corner.pdf', dpi=300, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the parameters of the simulations that have large errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda row: ddff.filter_function(row, error=[3, np.inf])\n",
    "high_error = df[df.apply(f, axis=1)].copy()\n",
    "print(f'found {len(res)} matching simulations ({len(high_error) / len(df):.1%})')\n",
    "\n",
    "f = ddff.histogram_corner(high_error, param_values, param_label=param_label,\n",
    "                          percent='per_bin', n_total=len(df), vmax=100)\n",
    "f.savefig('histogram_corner.pdf', dpi=300, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter one of the simulations which tend to have the highest errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda row: ddff.filter_function(row, error=[30, np.inf], alpha=1e-2, v_frag=100., M_star=param_values['M_star'][0])\n",
    "test = df[df.apply(f, axis=1)].copy()\n",
    "print(f'found {len(test)} matching simulations ({len(test) / len(df):.1%})')\n",
    "test_idx = np.random.choice(test.index)\n",
    "key = f'{test_idx:07d}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color:#D30\">Testing Area</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fname, 'r') as fh:\n",
    "    n_sim = len(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pick a random model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find one with $ \\alpha = 10^{-3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to select a random simulation out of as subset of all simulations\n",
    "# sims = pd.DataFrame(dipsy.utils.read_from_hdf5(fname))\n",
    "# key = f'{np.random.choice(np.random.choice(sims[sims.alpha==3e-3].index)):07d}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random key\n",
    "key = f'{int(n_sim * np.random.rand()):07d}'\n",
    "\n",
    "# previous issues:\n",
    "# key = '0006370'\n",
    "# key = '0006780' # disk depleted\n",
    "# key = '0000011' # disk depleted\n",
    "# key = '0001184'\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load the simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual simulation\n",
    "sim = dipsy.utils.read_from_hdf5(fname, key)\n",
    "it = sim['time'].searchsorted(t_disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting for dust lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'time': t_disk,    \n",
    "    'q' : 3.5,\n",
    "    'flux_fraction': 0.68,\n",
    "    'fname_in' : fname,\n",
    "    'fname_out' : 'test.hdf5',\n",
    "    'opac' : dipsy.Opacity(input='ricci_compact.npz'),\n",
    "    'fct_nr' : 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import estimator\n",
    "reload(estimator)\n",
    "import analysis_mass\n",
    "reload(analysis_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = analysis_mass.parallel_analyze(key, settings=settings, debug=True, progress=True, n_burnin=400, n_steps=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lams / (2 * np.pi)\n",
    "\n",
    "p_gas = [res[k] for k in ['N_g', 'rc_g', 'p_g']]\n",
    "p_dust = [res[k] for k in ['N_d', 'rc_d', 'p_d']]\n",
    "\n",
    "masses_g = res['masses_g']\n",
    "masses_d = res['masses_d']\n",
    "sampler_g = res['sampler_g']\n",
    "sampler_d = res['sampler_d']\n",
    "\n",
    "y_dust = res['sig_d_lbp']\n",
    "y_gas = res['sig_g_lbp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check intensity fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = sim['r'] / au\n",
    "obs = res['obs']\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(12, 5))\n",
    "gs = fig.add_gridspec(4, 4)\n",
    "ax = fig.add_subplot(gs[:4, :2])\n",
    "ax.set_xlabel(r'$r$ [au]')\n",
    "ax.set_ylabel(r'$I_\\nu$ [erg/(s cm$^2$ Hz sr)]')\n",
    "\n",
    "for ilam in np.arange(len(lams)):\n",
    "    \n",
    "    # find the best match\n",
    "    sampler = res['samplers'][ilam]\n",
    "    discard = res['discards'][ilam]\n",
    "    slice = sampler.lnprobability[:, discard:]\n",
    "    idx = np.unravel_index(slice.argmax(), slice.shape)\n",
    "    ln_best = slice[idx[0], idx[1]]\n",
    "    p_best  = sampler.chain[:, discard:, :][idx[0], idx[1], :]\n",
    "    _r_best = p_best[-1]\n",
    "    print(f'r_best = {_r_best:.2g} au')\n",
    "    \n",
    "    txt = f'$\\lambda = {lams[ilam] * 1e4:.0f}$ micron'\n",
    "    \n",
    "    # plot the model and determined dust line\n",
    "    \n",
    "    line, = ax.loglog(x, obs.I_nu[ilam], label=txt)\n",
    "    ax.axvline(_r_best, c=line.get_color(), ls=':')\n",
    "    \n",
    "    # plot the logp evolution\n",
    "    \n",
    "    col = ilam//2\n",
    "    row = ilam%2\n",
    "    ax2 = fig.add_subplot(gs[2+row, 2+col])\n",
    "    ax2.semilogy(-sampler.lnprobability.T, c='k', alpha=0.3);\n",
    "    ax2.set_ylim(top=1e5)\n",
    "    ax2.set_title(txt, {'color':line.get_color()})\n",
    "    ax2.set_xlabel('iteration #')\n",
    "    ax2.set_ylabel(r'$-\\log P$')\n",
    "    \n",
    "    # overplot the fit\n",
    "    \n",
    "    if settings['fct_nr'] == 3:\n",
    "        ym = dipsy.fortran.pwr2_logit(p_best, x)\n",
    "    elif settings['fct_nr'] == 1:\n",
    "        ym = dipsy.fortran.pwr1(p_best, x)\n",
    "    ax.loglog(x, ym, c=line.get_color(), ls='--')\n",
    "    \n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlim(.05, 1e3)\n",
    "ax.set_ylim(dipsy.fortran.crop, 1e2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the mass estimates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Gas:\\n====')\n",
    "print(f\"trapz-based mass off by factor of {res['M_g_est'] / res['M_gas']:.2g}\")\n",
    "print(f\"integral-based mass off by factor of {res['M_g_lbp'] / res['M_gas']:.2g}\")\n",
    "print(f\"integral-masses avg off by factor of {res['M_g_med'] / res['M_gas']:.2g}\")\n",
    "\n",
    "print('\\nDust:\\n====')\n",
    "print(f\"trapz-based mass off by factor of {res['M_d_est'] / res['M_dust']:.2g}\")\n",
    "print(f\"integral-based mass off by factor of {res['M_d_lbp'] / res['M_dust']:.2g}\")\n",
    "print(f\"integral-masses avg off by factor of {res['M_d_med'] / res['M_dust']:.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the particle size estimates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.loglog(sim['r'] / au, sim['a_dr'][it], '-', label='$a_\\mathrm{drift}$')\n",
    "ax.loglog(sim['r'] / au, sim['a_fr'][it], '-', label='$a_\\mathrm{frag}$')\n",
    "\n",
    "for _a, _r in zip(a, res['r_dust']):\n",
    "    ax.axvline(_r, c='k', lw=0.5)\n",
    "    ax.plot([_r], [_a], 'kx')\n",
    "ax.legend()\n",
    "ax.set_xlim(1e0, 1e3)\n",
    "ax.set_ylim(1e-4, 1e0)\n",
    "ax.set_xlabel(r'$r$ [au]')\n",
    "ax.set_ylabel(r'$a$ [cm]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the LBP fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the LBP sampler convergence\n",
    "\n",
    "f, ax = plt.subplots(2, 2)\n",
    "ax[0, 0].semilogy(-sampler_g.lnprobability.T);\n",
    "ax[1, 0].semilogy(-sampler_d.lnprobability.T);\n",
    "\n",
    "# plot the distribution of mass estimates\n",
    "\n",
    "ax[0, 1].hist(np.log10(masses_g / res['M_gas']));\n",
    "ax[1, 1].hist(np.log10(masses_d / res['M_dust']));\n",
    "\n",
    "for _ax in ax[0]:\n",
    "    _ax.set_title('gas')\n",
    "for _ax in ax[1]:\n",
    "    _ax.set_title('dust')\n",
    "    \n",
    "f.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the dust and gas LBP fits with uncertainties\n",
    "\n",
    "def wrapper(x, *args):\n",
    "    return dipsy.fortran.lbp_profile(args, x)\n",
    "\n",
    "y_d_min, y_d_max, y_d_array = estimator.get_sigma_area(sampler_d, wrapper, sim['r'], return_y=True)\n",
    "y_g_min, y_g_max, y_g_array = estimator.get_sigma_area(sampler_g, wrapper, sim['r'], return_y=True)\n",
    "\n",
    "# plot gas and dust surface densities\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "ax.loglog(res['r_dust'], res['sig_g'], 'C0x', label='Powell, gas')\n",
    "ax.loglog(res['r_dust'], res['sig_d'], 'C1x', label='drift estimate')\n",
    "\n",
    "ax.loglog(sim['r'] / au, sim['sig_g'][it], 'C0-', label='simulation, gas')\n",
    "ax.loglog(sim['r'] / au, sim['sig_d'][it], 'C1-', label='simulation, dust')\n",
    "\n",
    "ax.loglog(sim['r'] / au, y_gas, 'C0--', label='LBP, gas')\n",
    "ax.loglog(sim['r'] / au, y_dust, 'C1--', label='LBP, dust')\n",
    "\n",
    "ax.fill_between(sim['r'] / au, y_g_min, y_g_max, fc='C0', alpha=0.2)\n",
    "ax.fill_between(sim['r'] / au, y_d_min, y_d_max, fc='C1', alpha=0.2)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylim(1e-5, 1e3)\n",
    "ax.set_xlim(1e0, 5e2)\n",
    "ax.set_xlabel(r'$r$ [au]')\n",
    "ax.set_ylabel(r'$\\Sigma$ [g/cm$^2$]')\n",
    "fig.savefig('surface_densities.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check parameter guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = dipsy.get_observables(\n",
    "    sim['r'],\n",
    "    sim['sig_g'][it],\n",
    "    sim['sig_d'][it],\n",
    "    sim['a_max'][it],\n",
    "    sim['T'][it],\n",
    "    settings['opac'],\n",
    "    lams,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipsy.fortran.crop=1e-10\n",
    "ilam = -1\n",
    "\n",
    "x = sim['r'] / au\n",
    "y = obs.I_nu[ilam]\n",
    "mask = x>1\n",
    "x = x[mask]\n",
    "y = y[mask]\n",
    "p_guess, di = estimator.guess(x, y, 10, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 1, sharex=True, figsize=(8,8))\n",
    "\n",
    "ax[0].loglog(x, y, 'k', lw=2)\n",
    "for _p in p_guess:\n",
    "    ax[0].loglog(x , dipsy.fortran.pwr2_logit(_p, x), 'g', alpha=0.5, lw=1)\n",
    "    print('{:.2f}'.format(dipsy.fortran.lnp_pwr2_logit(_p, x, y)))\n",
    "\n",
    "ax[1].semilogx(di['x'], di['exponent2'])\n",
    "\n",
    "ax[1].axvline(di['r_dust'], c='r', lw=1, label=r'$r_\\mathrm{dust}$')\n",
    "ax[1].axvline(di['r_out'], c='k', lw=2, label=r'$r_\\mathrm{out}$')\n",
    "for _r in di['r_list']:\n",
    "    ax[1].axvline(_r, c='k', lw=1, ls=':')\n",
    "    \n",
    "ax[1].legend()\n",
    "ax[1].set_xlim(left=1);\n",
    "ax[0].set_ylim(dipsy.fortran.crop, 1e4);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
